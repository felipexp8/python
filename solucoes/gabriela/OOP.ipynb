{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício Orientação à Objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FileFunctions:\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filep = open(filename,\"r\")\n",
    "        self.strings = None\n",
    "        self.frequence = None\n",
    "        self.stopwords = [\"a\",\"e\",\"o\",\"as\",\"os\",\"de\",\"para\",\"sem\",\"com\"]\n",
    "\n",
    "    # Texto como lista de strings\n",
    "    def read_file(self):\n",
    "        s = []\n",
    "        for line in self.filep:\n",
    "            s.extend(line.strip().split(\" \"))\n",
    "        self.strings = s\n",
    "\n",
    "    # Retorna individualmente cada palavra\n",
    "    # Conta a quantidade de ocorrencia de cada palavra\n",
    "    def count_frequence(self):\n",
    "        d = {}\n",
    "        for word in self.strings:\n",
    "            if word in d:\n",
    "                d[word]+=1\n",
    "            else:\n",
    "                d[word]=1\n",
    "        self.frequence = d\n",
    " \n",
    "    # 10 palavras mais frequentes\n",
    "    def most_frequent(self, num):\n",
    "        d = self.frequence\n",
    "        return (sorted(d, key=d.get, reverse=True)[:10])\n",
    "\n",
    "    # Retorna a media e o desvio padrao das ocorrencias\n",
    "    def mean_std(self):\n",
    "        dicti = self.frequence\n",
    "\n",
    "        total = 0\n",
    "        for key in dicti:\n",
    "            total += dicti[key]\n",
    "\n",
    "        values = [dicti[i] for i in dicti]\n",
    "        std = np.std(values)\n",
    "\n",
    "        return total/len(dicti), std\n",
    "\n",
    "    # Novo arquivo eliminando todas as StopWords do texto\n",
    "    def delete_stopwords(self, outfile_name):\n",
    "        new_strings = []\n",
    "        for word in self.strings:\n",
    "            if word not in self.stopwords:\n",
    "                new_strings.append(word)\n",
    "\n",
    "        outfile = open(outfile_name,\"w+\")\n",
    "        for word in new_strings:\n",
    "            outfile.write(word+\" \")\n",
    "        outfile.close()\n",
    "\n",
    "    # distancia entre duas palavras\n",
    "    # hamming adaptado\n",
    "    def distance_words (self, word1, word2):\n",
    "        dist = 0\n",
    "        for i in range(min(len(word1),len(word2))):\n",
    "            if word1[i] != word2[i]:\n",
    "                dist+=1\n",
    "        dist += abs(len(word1)-len(word2))\n",
    "        return dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 2, 'pontuacao': 1, 'e': 3, 'um': 1, 'texto': 1, 'de': 5, 'fica': 1, 'as': 3, 'causando': 1, 'ambiguidades': 1, 'com': 2, 'ainda': 1, 'mais': 1, 'se': 2, 'você': 1, 'nao': 2, 'botar': 1, 'acento': 1, 'o': 1, 'foi': 1, 'muito': 2, 'importante': 1, 'os': 1, 'na': 1, 'lingua': 1, 'portuguesa': 1, 'sempre': 1, 'tanto': 1, 'que': 1, 'voce': 1, 'dificil': 1, 'entender': 1} \n",
      "\n",
      "\n",
      "Top 10 most frequent words:  ['de', 'e', 'as', 'a', 'com', 'se', 'nao', 'muito', 'pontuacao', 'um'] \n",
      "\n",
      "\n",
      "Mean:  1.40625  Standard Deviation:  0.8609360821222444\n"
     ]
    }
   ],
   "source": [
    "p1 = FileFunctions(\"test.txt\")\n",
    "p1.read_file()\n",
    "p1.count_frequence()\n",
    "print(p1.frequence,'\\n\\n')\n",
    "\n",
    "most10 = p1.most_frequent(10)\n",
    "print(\"Top 10 most frequent words: \",most10,'\\n\\n')\n",
    "\n",
    "mean, std = p1.mean_std()\n",
    "print(\"Mean: \",mean,\" Standard Deviation: \",std)\n",
    "\n",
    "p1.delete_stopwords(\"testout.txt\")\n",
    "\n",
    "word1 = input(\"Insira uma palavra: \")\n",
    "word2 = input(\"Insira outra palavra: \")\n",
    "dist = p1.distance_words(word1,word2)\n",
    "print(\"Distancia entre palavras: \",dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test] *",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
